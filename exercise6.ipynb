{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd1f4df8-27a4-474f-996a-a9d2335ed45d",
   "metadata": {},
   "source": [
    "\n",
    "# Exercise 1\n",
    "Paper link: https://arxiv.org/abs/1412.6572 \n",
    "\n",
    "As always, we want you to complete the missing code pieces marked with a \"TODO\". The code itself implements the FGSM (Fast Gradient Sign Method) which you have discussed in the previous lecture.\n",
    "\n",
    "a) \n",
    "Complete the \"TODO a)\"'s to create an untargeted FGSM.\n",
    "    \n",
    "b)\n",
    "Complete the \"TODO b)\"'s to create a targeted FGSM.\n",
    "    \n",
    "c)\n",
    "- Describe why a too small $eps$ does not or only hardly cause the model to make false predictions.\n",
    "- Describe what can be the problem when using an $eps$ that is too big.\n",
    "- Assume you want to create an optimal adversarial example. By \"optimal\" we mean that by simply looking at its image with the human eye, you would label the example much differently from how your trained model does. Also, you would not expect that any manipulation had happened to the original image (e.g., no artifacts are visible).\n",
    "    - Describe how you would go about creating such an adversarial example. What parameters are important and how would you choose them?\n",
    "    - Please create an example for this \"optimal\" adversarial example. Plot the image and what the model predicts as its label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Downloading helper files...<p>(Run this cell first!)\n",
    "import urllib.request\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/priv-sec/twai/master/exercise6_data/mnist_cnn.pt\", \"mnist_cnn.pt\"),\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/priv-sec/twai/master/exercise6_data/MnistNet.py\", \"MnistNet.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2dae18e-aed3-4b27-b83b-6b22d92cc995",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from MnistNet import Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3190498f-1287-4b9a-914a-772c0db7afed",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "model = Net().to(device)\n",
    "model.load_state_dict(torch.load(\"./mnist_cnn.pt\"))  # Load pre-trained weights\n",
    "model.eval()  # Avoid any backpropagation\n",
    "\n",
    "dataset = datasets.MNIST('./data', train=False, download=True, transform=transforms.ToTensor())\n",
    "data_loader = torch.utils.data.DataLoader(dataset, **{\"batch_size\": 1, \"shuffle\": True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0098e7-78aa-4c4c-b7d8-bfc3518141ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 1  # Upper bound for the noise\n",
    "eps_step = 1/20  # Increase of the noise\n",
    "\n",
    "# In case of a targeted attack we need to specify the targeted class\n",
    "target_label = None  \n",
    "#target_label = torch.Tensor([0]).type(torch.LongTensor).to(device)\n",
    "targeted = target_label != None  # True if <target_label> != None else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507a75a0-45e8-460f-8242-3717ff3b679a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grad_signs(x, y):\n",
    "    \"\"\"\n",
    "    Feed the given input into the model and get the gradient wrt the desired label.\n",
    "    The FGSM only requires the signs of the gradient.\n",
    "    \n",
    "    :param data: A single image\n",
    "    :param label: The desired output label\n",
    "    \n",
    "    :return: The sign of the created gradient wrt the desired label\n",
    "    \"\"\"\n",
    "\n",
    "    # Forward propagate input\n",
    "    output = model(x)\n",
    "    \n",
    "    # Create desired gradients\n",
    "    # Note: Use <F.nll_loss> as loss funtion\n",
    "    loss = # TODO a) # \n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    # Get signs of gradient [[0.5, 0, -0.7, 3], ...] -> [[1, 0, -1, 1], ...]\n",
    "    # Note: Use <x.grad.data> to access the gradient\n",
    "    sign = # TODO a) # \n",
    "    \n",
    "    # Invert every sign in case of a targeted attack\n",
    "    if targeted:\n",
    "        # TODO b) #\n",
    "        pass\n",
    "    \n",
    "    return sign\n",
    "\n",
    "\n",
    "def apply_perturbation(x, gradient_signs, eps):\n",
    "    \"\"\"\n",
    "    Apply a perturbation onto the given image.\n",
    "    The strength of the applied perturbation is controlled by <eps>.\n",
    "    \n",
    "    :param x: A single image\n",
    "    :param gradient_signs: The signs of the gradient with the same shape as the input image\n",
    "    :param eps: A skalar which controlles the strength of the applied perturbation\n",
    "    \n",
    "    :return: A modified version of the given image\n",
    "    \"\"\"\n",
    "        \n",
    "    # Calculate perturbation -> eps * sign(gradient)\n",
    "    perturbation = # TODO a) #\n",
    "    \n",
    "    # Add perturbation to the image\n",
    "    x = x + perturbation\n",
    "    \n",
    "    # Ensure that every pixel value is still in the interval [0,1]\n",
    "    x = # TODO a) # \n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02138b8c-e018-4bdc-bb89-7669538e4eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimal_perturbation(x, y):\n",
    "    \"\"\"\n",
    "    Try to find a perturbation based on a minimal epsilon such that...\n",
    "    a) Untargeted attack: the model classifies the given image into an arbitrary class\n",
    "    b) Targeted attack: the model classifies the given image into the class <target_label>\n",
    "    \n",
    "    :param x: A single image\n",
    "    :param y: The original class label of the given image\n",
    "    \n",
    "    :return: (adversarial example, new label) as tuple or None if no adversarial example could be generated\n",
    "    \"\"\"\n",
    "    \n",
    "    # In case of a targeted attack set the desired label\n",
    "    if targeted:\n",
    "        y = target_label\n",
    "    \n",
    "    # Get signs of the desired gradient\n",
    "    gradient_signs = get_grad_signs(x, y)\n",
    "\n",
    "    current_eps = eps_step\n",
    "    partial_stop_condition = current_eps <= eps\n",
    "    \n",
    "    while partial_stop_condition:\n",
    "        \n",
    "        current_adv_x = apply_perturbation(x, gradient_signs, current_eps)\n",
    "    \n",
    "        # Predict new label\n",
    "        adv_preds = # TODO a) # \n",
    "        new_label = adv_preds.argmax(dim=1, keepdim=True)[0].cpu().detach()\n",
    "        \n",
    "        # Untargeted attack: Check if we get another arbitrary label\n",
    "        if not targeted:\n",
    "            flipped = # TODO a) #\n",
    "        # Targeted attack: Check if we get the desired label\n",
    "        else:\n",
    "            flipped = # TODO b) #\n",
    "    \n",
    "        # Update current eps and check the stop condition\n",
    "        current_eps += eps_step\n",
    "        partial_stop_condition = current_eps <= eps\n",
    "        \n",
    "        # If we successfully generated an adversarial example then save it in combination with its new label\n",
    "        if flipped:\n",
    "            return current_adv_x.detach().cpu(), new_label\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681824d8-14ce-429a-b28a-66ba62bdf7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(data_loader, device):\n",
    "    \"\"\"\n",
    "    Iterates the given dataset and tries to find an adversarial example for every image.\n",
    "    \n",
    "    :param data_loader: Dataset packed in an iterable data loader\n",
    "    :param device: PyTorch device \n",
    "    \n",
    "    :return: A list of adversarial examples with the following structure \n",
    "             [(original_img, original_label, adversarial_img, adversarial_label), ...]\n",
    "    \"\"\"\n",
    "        \n",
    "    x_advs = list()\n",
    "\n",
    "    for i, (data, label) in enumerate(data_loader):\n",
    "\n",
    "        data, label = data.to(device), label.to(device)\n",
    "        data.requires_grad = True  # To generate gradients...\n",
    "        \n",
    "        # This does not make much sense...\n",
    "        if targeted:\n",
    "            if label == target_label:\n",
    "                continue\n",
    "        \n",
    "        # Search for an adversarial example\n",
    "        x_adv = minimal_perturbation(data, label)\n",
    "        if x_adv != None:\n",
    "            x_advs.append( (data.detach().cpu(), label.detach().cpu(), *x_adv) )\n",
    "            \n",
    "        # You don't have to iterate all 10,000 images...\n",
    "        if i >= 100:\n",
    "            break\n",
    "            \n",
    "    return x_advs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbded1c8-14ed-46d1-9b15-7223d8895cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_examples = generate(data_loader, device)\n",
    "\n",
    "print(f\"Found {len(adv_examples)} adversarial examples...\")\n",
    "\n",
    "# Use this to plot some images and their corresponding adversarial versions\n",
    "for org, org_label, adv, adv_label in adv_examples:\n",
    "    \n",
    "    plt.imshow(org[0][0])\n",
    "    plt.title(f\"Label: {org_label}\")\n",
    "    plt.show()\n",
    "    \n",
    "    plt.imshow(adv[0][0])\n",
    "    plt.title(f\"Label: {adv_label}\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch (1 gpu)",
   "language": "python",
   "name": "pytorch-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}