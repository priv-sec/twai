{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "exercise5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python377jvsc74a57bd000fe828615db63367d4538dea818edeccf45ed831be4f445733eae33643b3f7b",
      "display_name": "Python 3.7.7 64-bit"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title Downloading helper files...<p>(Run this cell first!)\\n\",\n",
        "import urllib.request\n",
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/priv-sec/twai/master/exercise5_data/binary_model.py\", \"binary_model.py\"),\n",
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/priv-sec/twai/master/exercise5_data/cifar10_model.py\", \"cifar10_model.py\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HrcITdhLpnS"
      },
      "source": [
        "## Membership Inference Attack (Salem et al.)\n",
        "\n",
        "**1) Preprocess the Cifar10 dataset**\n",
        "\n",
        "**2) Train target model**\n",
        "\n",
        "**3) Train shadow model**\n",
        "\n",
        "**4) Train attack model**\n",
        "\n",
        "**5) Attack evaluation**\n",
        "\n",
        "\n",
        "\n",
        "Task: Please fill out the #TODOs# in the code below.\n",
        "\n",
        "Note:\n",
        "  - The target and shadow model should reach an accuracy above 95%. If the accuracy is below 95% you should consider to re-train the respective model\n",
        "  - Your attack works if the accuracy calculated in the last cell is at least above 60%"
      ]
    },
    {
      "source": [
        "## Preprocess the Cifar10 dataset\n",
        "\n",
        "Split the dataset into fore subsets to train and test the target and shadow model."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yl2W4n2OJgLk"
      },
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from cifar10_model import Cifar10Net, train_cifar10_model\n",
        "from binary_model import BinaryNet, train_binary_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "TRAIN_BATCHSIZE = 32\n",
        "TEST_BATCHSIZE = 1000\n",
        "\n",
        "EPOCHS_CIFAR10 = 30\n",
        "EPOCHS_BINARY = 10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4hwNcHvJCyM"
      },
      "source": [
        "def get_cifar10_dataset(root_dir=\"./data\"):\n",
        "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "    train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "    test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "    return train_dataset, test_dataset\n",
        "\n",
        "\n",
        "def split_dataset(dataset):\n",
        "\n",
        "    train_target_indices, test_target_indices, train_shadow_indices, test_shadow_indices = \\\n",
        "                 torch.utils.data.random_split(dataset, [len(dataset)//4]*4)\n",
        "\n",
        "    train_target = torch.utils.data.DataLoader(train_target_indices, **train_kwargs)\n",
        "    test_target = torch.utils.data.DataLoader(test_target_indices, **test_kwargs)\n",
        "    train_shadow = torch.utils.data.DataLoader(train_shadow_indices, **train_kwargs)\n",
        "    test_shadow = torch.utils.data.DataLoader(test_shadow_indices, **test_kwargs)\n",
        "\n",
        "    return (train_target, test_target), (train_shadow, test_shadow)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPCV6eun7Fsf"
      },
      "source": [
        "cuda_available = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if cuda_available else \"cpu\")\n",
        "\n",
        "train_kwargs = {\n",
        "    'batch_size': TRAIN_BATCHSIZE,\n",
        "    'shuffle': True\n",
        "    }\n",
        "\n",
        "test_kwargs = {\n",
        "    'batch_size': TEST_BATCHSIZE,\n",
        "    'shuffle': True\n",
        "    }\n",
        "\n",
        "if cuda_available:\n",
        "    cuda_kwargs = {\n",
        "        'num_workers': 2,\n",
        "        'pin_memory': True,\n",
        "        'shuffle': True\n",
        "        }\n",
        "    train_kwargs.update(cuda_kwargs)\n",
        "    test_kwargs.update(cuda_kwargs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFhVoxXw7Gby"
      },
      "source": [
        "train_dataset, test_dataset = get_cifar10_dataset()\n",
        "\n",
        "(train_target_loader, test_target_loader), (train_shadow_loader, test_shadow_loader) = split_dataset(train_dataset + test_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZ0qFwwsgXWL"
      },
      "source": [
        "## Target Model\n",
        "\n",
        "Here, we train the target model which we would usually get as input without additional background knowledge."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_E9JcaagW27"
      },
      "source": [
        "target_model = Cifar10Net().to(device)\n",
        "# TODO: Train target model with target data # "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAMIfBY8NJzx"
      },
      "source": [
        "## Shadow Model\n",
        "\n",
        "Here, we train a shadow model which has the same architecture as the target model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzm4Ix8ZK3Bl"
      },
      "source": [
        "shadow_model = Cifar10Net().to(device)\n",
        "# TODO: Train shadow model with shadow data # "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vENn-riuNOvp"
      },
      "source": [
        "## Top-k classes\n",
        "\n",
        "The advantage of the shadow model is that we know exactly which points were used for training which for testing. Therefore, we can use this knowledge to create our own IN/OUT dataset to hopefully learn something."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def getTopk(data, top):\n",
        "    \"\"\"\n",
        "    Returns the top k maximum entries of the given data.\n",
        "    \"\"\"\n",
        "    return # TODO #\n",
        "\n",
        "\n",
        "softmax = torch.nn.Softmax(dim=0)\n",
        "\n",
        "def predict_(model, data_loader):\n",
        "    \"\"\"\n",
        "    Iterates the given data_loader and collects the predicition vectors\n",
        "    of the given model in a list.\n",
        "    Note: It is essential for this attack to apply the softmax function \n",
        "          DIRECTLY AFTER receiving the prediction vector\n",
        "    \"\"\"\n",
        "    preds = list()\n",
        "    with torch.no_grad():\n",
        "        # TODO #\n",
        "    return preds"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ku9mtzkaND_f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd2e0067-6717-47d2-ed95-9740098b98dd",
        "tags": []
      },
      "source": [
        "# IN\n",
        "shadow_preds_IN = predict_( shadow_model, train_shadow_loader )\n",
        "shadow_labels_IN = # TODO: Create appropriate amount of ones #\n",
        "\n",
        "# OUT\n",
        "shadow_preds_OUT = predict_( shadow_model, test_shadow_loader )\n",
        "shadow_labels_OUT = # TODO: Create appropriate amount of zeros #\n",
        "\n",
        "# ALL = IN + OUT\n",
        "shadow_preds = np.concatenate([shadow_preds_IN, shadow_preds_OUT])\n",
        "shadow_labels = np.concatenate([shadow_labels_IN, shadow_labels_OUT])\n",
        "\n",
        "# Top 3 prediction values\n",
        "shadow_preds = getTopk(shadow_preds, 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "attack_dataset = torch.utils.data.TensorDataset(torch.Tensor(shadow_preds).type(torch.FloatTensor), torch.Tensor(shadow_labels).type(torch.LongTensor) )\n",
        "train_attacker_loader = torch.utils.data.DataLoader(attack_dataset, **train_kwargs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBgolFVTNSUx"
      },
      "source": [
        "## Attack Model\n",
        "\n",
        "Our attacker model is a binary classifier which tries to classify the top 3 maximum entries of a specific prediction vector into one of two classes: Inside the training set or inside the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pz21jeHVOkCd",
        "tags": []
      },
      "source": [
        "attack_model = BinaryNet().to(device)\n",
        "train_binary_model(attack_model, device, train_attacker_loader, EPOCHS_BINARY)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeJQuRFtNeeR"
      },
      "source": [
        "## Evaluation\n",
        "\n",
        "Now, we want to evaluate the accuracy of our attack model. Therefore we iterate every training point and check whether the predicted label is correct or not."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LowDJFdBNe4J",
        "tags": []
      },
      "source": [
        "# IN\n",
        "target_preds_IN = predict_( target_model, train_target_loader )\n",
        "target_labels_IN = # TODO: Create appropriate amount of ones #\n",
        "\n",
        "# OUT\n",
        "target_preds_OUT = predict_( target_model, test_target_loader )\n",
        "target_labels_OUT = # TODO: Create appropriate amount of zeros #\n",
        "\n",
        "# ALL = IN + OUT\n",
        "target_preds = np.concatenate([target_preds_IN, target_preds_OUT])\n",
        "target_labels = np.concatenate([target_labels_IN, target_labels_OUT])\n",
        "\n",
        "# Top 3 prediction values\n",
        "target_preds = getTopk(target_preds, 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Evlo2d98y0pM",
        "tags": []
      },
      "source": [
        "eval_dataset = torch.utils.data.TensorDataset(torch.Tensor(target_preds).type(torch.FloatTensor), torch.Tensor(target_labels).type(torch.LongTensor) )\n",
        "train_eval_loader = torch.utils.data.DataLoader(eval_dataset)\n",
        "\n",
        "correct_preds = 0\n",
        "with torch.no_grad():\n",
        "    for data, target in train_eval_loader:\n",
        "        x, y = data.to(device), target.to(device)\n",
        "        # TODO: Use <attack_model> to make predictions #\n",
        "        # TODO: For every correct prediction increment <correct_preds> #\n",
        "        # Note: Maybe <.detach()> and <.cpu()> are required to access specific tensors #\n",
        "\n",
        "print(\"Accuracy\", correct_preds / 30000)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}